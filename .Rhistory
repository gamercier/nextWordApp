# Load the testing data
#  test_quads_dev.r -- test data for development, 1000 quads news text, non web
#     source: 12dicts-6.0.2_bench_1.zip
#     http://www.anc.org/OANC/OANC_GrAF.zip
#     This is from the American National Corpus: http://www.anc.org/
#  test_web_dev.r -- test data for development, 1000 quads from HCcorpora
#  test_web_test.r -- test data for final testing, 1000 quads from HCcorpora
source("toTesting.R")
##### Set test data set - REQUIRED
test.file <- "test_quads_dev.r"
test.file <- file.path(getwd(),test.file)
load(test.file)
print(paste("Loaging test data set file",test.file))
print(paste("Loaded test data:",ls(pattern="sample")))
setwd(prj.dir)
print(paste("Returning directory to",getwd()))
##### Load the scores database and set the global variables
source("toDbs.R")
dir()
##### Set scores database - REQUIRED
scores.dir <- file.path(dbs.dir,"10.dir")
setwd(scores.dir)
dir()
scores.file <- "scoresSB.trimmed.dense.r"
load(scores.file)
print(paste("Loaging scores file",scores.file))
print(paste("Loaded scores database:",
ls(pattern="^(bases|ngrams|scores)\\.[a-zA-Z0-9\\.]*db")))
scoresDB <-  scores.trimmed.dense.db$ten.pct
ngramsDB <-  ngrams.trimmed.dense.db$ten.pct
basesDB  <-  bases.trimmed.dense.db$ten.pct
TOP.UNI.SCORES <- scoresDB$unigram[1:3] # presumed to be sorted with higher score first
ALPHA <- 0.4
str(scoresDB)
str(ngramsDB)
setwd(prj.dir)
print(paste("Returning directory to",getwd()))
rm(list=ls())
# Capstone Project
# File: probeGuess.R
# Tests guessing function against a database of quadgrams in nlpData.dir/testing
# Move to testing directory and load the test dataset
prj.dir <- file.path(Sys.getenv("HOME"),"git","NLPCapstone")
print(paste("Moving to",prj.dir))
setwd(prj.dir)
print(paste("Current directory to",getwd()))
# helper functions
library(stringr)
# helper functions
toWords <- function(ngram) str_split(ngram,pattern=boundary("word"))
toStr <- function(words) lapply(words,str_c,collapse=" ")
dropFirstWord <- function(ngram) {
words <- toWords(ngram)
n <- length(words[[1]]) # no checks! Assumes all ngrams have same n
toStr(lapply(words,function(s) s[2:n]))
}
dropLastWord <- function(ngram){
words <- toWords(ngram)
toStr(lapply(words,function(s) { n<-length(s); s[1:(n-1)] }))
}
getLastWord <- function(ngram){
words <- toWords(ngram)
toStr(lapply(words,function(s) { tail(s,1) }))
}
countWords <- function(ngram) lapply(toWords(ngram),length)
toSpace <- function(x, pattern, ...){
return(gsub(pattern," ", x, ...))
}
toNone <- function(x, pattern, ...){
return(gsub(pattern,"", x, ...))
}
top3 <- function(v){
n <- length(v)
hits <- sort(v,partial=c(n,n-1,n-2))[n:(n-2)]
idx <- unlist(sapply(hits, function(x) which(v == x)))
return(v[idx])
}
simple_guess.sb <- function(base_ngram){
words <- unlist(toWords(base_ngram))
n <- length(words)   # size of base_ngram. ngram size is n+1
nMax <- n
scores <- (ALPHA^nMax)*TOP.UNI.SCORES # ngram is unigram (base_ngram is ""), n=0
while(n>0){
base <- paste(words[(nMax-n+1):nMax],collapse=" ")
hits <- base == basesDB[[n]]  # basesDB[[n]] has base for ngramsDB[[(n+1)]]
if(sum(hits)){
# scores <- c(scores,(ALPHA^(nMax-n))*scoresDB[[(n+1)]][ ngramsDB[[(n+1)]][hits] ])
scores <- c(scores,(ALPHA^(nMax-n))*scoresDB[[(n+1)]][ hits ])
}
n <- n-1
}
guesses <- top3(scores)
data.frame(guess=unlist(getLastWord(names(guesses)))[1:3],
scores=guesses[1:3],row.names=c("1st","2nd","3rd"))
}
guess.sb <- simple_guess.sb
##########  automating testing
testing <- function(test.s){
hit <- function(x){
output <- guess.sb(unlist(dropLastWord(x)))
if(unlist(getLastWord(x)) %in% output$guess){
return(list(hit=TRUE,answer=output))
} else {
return(list(hit=FALSE,answer=output))
}
}
test.f <- lapply(test.s,hit)
names(test.f) <- as.character(1:length(test.s))
return(test.f)
}
# testing.answer <- function(test.s){
#   hit <- function(x,a=a){
#     guesses <- guess.sb(unlist(dropLastWord(x)))$guess
#     if(unlist(getLastWord(x)) %in% guesses){
#       return(TRUE)
#     } else {
#       return(FALSE)
#     }
#   }
#   test.f <- sapply(test.s,hit)
#   # returns the actual test quadgram that got guessed correctly (within top 3)
#   return(test.s[test.f])
# }
# Load the testing data
#  test_quads_dev.r -- test data for development, 1000 quads news text, non web
#     source: 12dicts-6.0.2_bench_1.zip
#     http://www.anc.org/OANC/OANC_GrAF.zip
#     This is from the American National Corpus: http://www.anc.org/
#  test_web_dev.r -- test data for development, 1000 quads from HCcorpora
#  test_web_test.r -- test data for final testing, 1000 quads from HCcorpora
source("toTesting.R")
##### Set test data set - REQUIRED
test.file <- "test_quads_dev.r"
test.file <- file.path(getwd(),test.file)
load(test.file)
print(paste("Loaging test data set file",test.file))
print(paste("Loaded test data:",ls(pattern="sample")))
setwd(prj.dir)
print(paste("Returning directory to",getwd()))
##### Load the scores database and set the global variables
source("toDbs.R")
dir()
##### Set scores database - REQUIRED
scores.dir <- file.path(dbs.dir,"10.dir")
setwd(scores.dir)
dir()
scores.file <- "scoresSB.trimmed.dense.r"
load(scores.file)
print(paste("Loaging scores file",scores.file))
print(paste("Loaded scores database:",
ls(pattern="^(bases|ngrams|scores)\\.[a-zA-Z0-9\\.]*db")))
scoresDB <-  scores.trimmed.dense.db$ten.pct
ngramsDB <-  ngrams.trimmed.dense.db$ten.pct
basesDB  <-  bases.trimmed.dense.db$ten.pct
TOP.UNI.SCORES <- scoresDB$unigram[1:3] # presumed to be sorted with higher score first
ALPHA <- 0.4
str(scoresDB)
str(ngramsDB)
# Do the test
alphas <- c(0.2,0.4,0.6,0.8)
print("Test: test_quads_dev.r; database: 10pct; method: stupid backoff")
print(paste("Scores database directory:",scores.dir))
print(paste("Scores file:",scores.file))
results <- list()
n.test <- length(test.sample)
for(alpha in alphas){
ALPHA <- alpha
results[[as.character(alpha)]] <- testing(test.sample)
n.hits <- sum(results[[as.character(alpha)]]$hit)
print(paste("Hits: ",sum(n.hits)," out of ",n.test,"alpha=",alpha))
}
head(test.sample)
guess.sb("from time to")
guess.sb("book book book")
guess.sb("happy mothers day")
guess.sb("is happy mothers")
guess.sb("martin luther king")
guess.sb("i am going")
guess.sb("what time is")
guess.sb("say good bye")
guess.sb("going home from")
str(results)
t <- results[[as.character(0.8)]]$hit
str(t)
t <- results[[as.character(0.8)]]
str(t)
results <- list()
n.test <- length(test.sample)
for(alpha in alphas){
ALPHA <- alpha
results[[as.character(alpha)]] <- testing(test.sample)
n.hits <- sum(sapply(results[[as.character(alpha)]],function(x) x$hit))
print(paste("Hits: ",sum(n.hits)," out of ",n.test,"alpha=",alpha))
}
# Do the test
alphas <- c(0.2,0.4,0.6,0.8)
print("Test: test_quads_dev.r; database: 10pct; method: stupid backoff")
print(paste("Scores database directory:",scores.dir))
print(paste("Scores file:",scores.file))
results <- list()
n.test <- length(test.sample)
for(alpha in alphas){
ALPHA <- alpha
results[[as.character(alpha)]] <- testing(test.sample)
n.hits <- sum(sapply(results[[as.character(alpha)]],function(x) x$hit))
print(paste("Hits: ",sum(n.hits)," out of ",n.test,"alpha=",alpha))
}
rm(list=ls())
source('~/git/NLPCapstone/makeFreqs.R')
rm(list=ls())
source('~/git/NLPCapstone/makeFreqs.R')
rm(list=ls())
source('~/git/NLPCapstone/makeFreqs.R')
rm(list=ls())
source('~/git/NLPCapstone/trimFreqs.R')
rm(list=ls())
source('~/git/NLPCapstone/trimFreqs.R')
rm(list=ls())
source('~/git/NLPCapstone/trimFreqs.R')
rm(list=ls())
source('~/git/NLPCapstone/makeScoresSB.R')
rm(list=ls())
source('~/git/NLPCapstone/makeScoresSB.R')
rm(list=ls())
source('~/git/NLPCapstone/makeScoresSB.R')
rm(list=ls())
# Capstone Project
# File: probeGuess.R
# Tests guessing function against a database of quadgrams in nlpData.dir/testing
# Move to testing directory and load the test dataset
prj.dir <- file.path(Sys.getenv("HOME"),"git","NLPCapstone")
print(paste("Moving to",prj.dir))
setwd(prj.dir)
print(paste("Current directory to",getwd()))
# helper functions
library(stringr)
# helper functions
toWords <- function(ngram) str_split(ngram,pattern=boundary("word"))
toStr <- function(words) lapply(words,str_c,collapse=" ")
dropFirstWord <- function(ngram) {
words <- toWords(ngram)
n <- length(words[[1]]) # no checks! Assumes all ngrams have same n
toStr(lapply(words,function(s) s[2:n]))
}
dropLastWord <- function(ngram){
words <- toWords(ngram)
toStr(lapply(words,function(s) { n<-length(s); s[1:(n-1)] }))
}
getLastWord <- function(ngram){
words <- toWords(ngram)
toStr(lapply(words,function(s) { tail(s,1) }))
}
countWords <- function(ngram) lapply(toWords(ngram),length)
toSpace <- function(x, pattern, ...){
return(gsub(pattern," ", x, ...))
}
toNone <- function(x, pattern, ...){
return(gsub(pattern,"", x, ...))
}
top3 <- function(v){
n <- length(v)
hits <- sort(v,partial=c(n,n-1,n-2))[n:(n-2)]
idx <- unlist(sapply(hits, function(x) which(v == x)))
return(v[idx])
}
simple_guess.sb <- function(base_ngram){
words <- unlist(toWords(base_ngram))
n <- length(words)   # size of base_ngram. ngram size is n+1
nMax <- n
scores <- (ALPHA^nMax)*TOP.UNI.SCORES # ngram is unigram (base_ngram is ""), n=0
while(n>0){
base <- paste(words[(nMax-n+1):nMax],collapse=" ")
hits <- base == basesDB[[n]]  # basesDB[[n]] has base for ngramsDB[[(n+1)]]
if(sum(hits)){
# scores <- c(scores,(ALPHA^(nMax-n))*scoresDB[[(n+1)]][ ngramsDB[[(n+1)]][hits] ])
scores <- c(scores,(ALPHA^(nMax-n))*scoresDB[[(n+1)]][ hits ])
}
n <- n-1
}
guesses <- top3(scores)
data.frame(guess=unlist(getLastWord(names(guesses)))[1:3],
scores=guesses[1:3],row.names=c("1st","2nd","3rd"))
}
guess.sb <- simple_guess.sb
##########  automating testing
testing <- function(test.s){
hit <- function(x){
output <- guess.sb(unlist(dropLastWord(x)))
if(unlist(getLastWord(x)) %in% output$guess){
return(list(hit=TRUE,answer=output))
} else {
return(list(hit=FALSE,answer=output))
}
}
test.f <- lapply(test.s,hit)
names(test.f) <- as.character(1:length(test.s))
return(test.f)
}
# testing.answer <- function(test.s){
#   hit <- function(x,a=a){
#     guesses <- guess.sb(unlist(dropLastWord(x)))$guess
#     if(unlist(getLastWord(x)) %in% guesses){
#       return(TRUE)
#     } else {
#       return(FALSE)
#     }
#   }
#   test.f <- sapply(test.s,hit)
#   # returns the actual test quadgram that got guessed correctly (within top 3)
#   return(test.s[test.f])
# }
# Load the testing data
#  test_quads_dev.r -- test data for development, 1000 quads news text, non web
#     source: 12dicts-6.0.2_bench_1.zip
#     http://www.anc.org/OANC/OANC_GrAF.zip
#     This is from the American National Corpus: http://www.anc.org/
#  test_web_dev.r -- test data for development, 1000 quads from HCcorpora
#  test_web_test.r -- test data for final testing, 1000 quads from HCcorpora
source("toTesting.R")
##### Set test data set - REQUIRED
test.file <- "test_quads_dev.r"
test.file <- file.path(getwd(),test.file)
load(test.file)
print(paste("Loaging test data set file",test.file))
print(paste("Loaded test data:",ls(pattern="sample")))
setwd(prj.dir)
print(paste("Returning directory to",getwd()))
##### Load the scores database and set the global variables
source("toDbs.R")
dir()
##### Set scores database - REQUIRED
scores.dir <- file.path(dbs.dir,"10.dir")
setwd(scores.dir)
dir()
scores.file <- "scoresSB.trimmed.dense.r"
load(scores.file)
print(paste("Loaging scores file",scores.file))
print(paste("Loaded scores database:",
ls(pattern="^(bases|ngrams|scores)\\.[a-zA-Z0-9\\.]*db")))
scoresDB <-  scores.trimmed.dense.db$ten.pct
ngramsDB <-  ngrams.trimmed.dense.db$ten.pct
basesDB  <-  bases.trimmed.dense.db$ten.pct
TOP.UNI.SCORES <- scoresDB$unigram[1:3] # presumed to be sorted with higher score first
ALPHA <- 0.4
# Do the test
alphas <- c(0.2,0.4,0.6,0.8)
print("Test: test_quads_dev.r; database: 10pct; method: stupid backoff")
print(paste("Scores database directory:",scores.dir))
print(paste("Scores file:",scores.file))
results <- list()
n.test <- length(test.sample)
for(alpha in alphas){
ALPHA <- alpha
results[[as.character(alpha)]] <- testing(test.sample)
n.hits <- sum(sapply(results[[as.character(alpha)]],function(x) x$hit))
print(paste("Hits: ",sum(n.hits)," out of ",n.test,"alpha=",alpha))
}
getwd()
save.file <- "dev_test_ac.r"
save(results,file=save.file)
print("Finished testing.")
setwd(prj.dir)
print(paste("Returning directory to",getwd()))
t <- results$as.character(0.2)
t <- results[[as.character(0.2)]]
t.hits <- lapply(t, function(x) x$hit)
str(t.hits)
t.hits <- sapply(t, function(x) x$hit)
str(t.hits)
t.ans <- t[t.hits]
str(t.ans)
t.ans[[1]]
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
db.element
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
test.file
tail(strsplit(test.file,"/"),1)
tail(unlist(strsplit(test.file,"/"),1))
tail(unlist(strsplit(test.file,"/")),1)
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
ls()
rm(list=ls())
# Capstone Project
# File: probeGuess.R
# Tests guessing function against a database of quadgrams in nlpData.dir/testing
# Move to testing directory and load the test dataset
prj.dir <- file.path(Sys.getenv("HOME"),"git","NLPCapstone")
print(paste("Moving to",prj.dir))
setwd(prj.dir)
print(paste("Current directory to",getwd()))
# helper functions
library(stringr)
# helper functions
toWords <- function(ngram) str_split(ngram,pattern=boundary("word"))
toStr <- function(words) lapply(words,str_c,collapse=" ")
dropFirstWord <- function(ngram) {
words <- toWords(ngram)
n <- length(words[[1]]) # no checks! Assumes all ngrams have same n
toStr(lapply(words,function(s) s[2:n]))
}
dropLastWord <- function(ngram){
words <- toWords(ngram)
toStr(lapply(words,function(s) { n<-length(s); s[1:(n-1)] }))
}
getLastWord <- function(ngram){
words <- toWords(ngram)
toStr(lapply(words,function(s) { tail(s,1) }))
}
countWords <- function(ngram) lapply(toWords(ngram),length)
toSpace <- function(x, pattern, ...){
return(gsub(pattern," ", x, ...))
}
toNone <- function(x, pattern, ...){
return(gsub(pattern,"", x, ...))
}
top3 <- function(v){
n <- length(v)
hits <- sort(v,partial=c(n,n-1,n-2))[n:(n-2)]
idx <- unlist(sapply(hits, function(x) which(v == x)))
return(v[idx])
}
# simple_guess_sb was modified 2016-09-18 stringsAsFactors = FALSE
simple_guess.sb <- function(base_ngram){
words <- unlist(toWords(base_ngram))
n <- length(words)   # size of base_ngram. ngram size is n+1
nMax <- n
scores <- (ALPHA^nMax)*TOP.UNI.SCORES # ngram is unigram (base_ngram is ""), n=0
while(n>0){
base <- paste(words[(nMax-n+1):nMax],collapse=" ")
hits <- base == basesDB[[n]]  # basesDB[[n]] has base for ngramsDB[[(n+1)]]
if(sum(hits)){
# scores <- c(scores,(ALPHA^(nMax-n))*scoresDB[[(n+1)]][ ngramsDB[[(n+1)]][hits] ])
scores <- c(scores,(ALPHA^(nMax-n))*scoresDB[[(n+1)]][ hits ])
}
n <- n-1
}
guesses <- top3(scores)
data.frame(guess=unlist(getLastWord(names(guesses)))[1:3],
scores=guesses[1:3],row.names=c("1st","2nd","3rd"),
stringsAsFactors = FALSE)
}
guess.sb <- simple_guess.sb
##########  automating testing
testing <- function(test.s){
hit <- function(x){
output <- guess.sb(unlist(dropLastWord(x)))
if(unlist(getLastWord(x)) %in% output$guess){
return(list(hit=TRUE,answer=output))
} else {
return(list(hit=FALSE,answer=output))
}
}
test.f <- lapply(test.s,hit)
names(test.f) <- as.character(1:length(test.s))
return(test.f)
}
# Load the testing data
#  test_quads_dev.r -- test data for development, 1000 quads news text, non web
#     source: 12dicts-6.0.2_bench_1.zip
#     http://www.anc.org/OANC/OANC_GrAF.zip
#     This is from the American National Corpus: http://www.anc.org/
#  test_web_dev.r -- test data for development, 1000 quads from HCcorpora
#  test_web_test.r -- test data for final testing, 1000 quads from HCcorpora
source("toTesting.R")
##### Set test data set - REQUIRED
test.file <- "test_web_dev.r"
test.file <- file.path(getwd(),test.file)
load(test.file)
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
str(test.quads.dev)
tail(unlist(strsplit(test.file,"/")),1)
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
source('~/git/NLPCapstone/trimFreqs.R')
rm(list=ls())
source('~/git/NLPCapstone/makeScoresSB.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
rm(list=ls())
source('~/git/NLPCapstone/testGuess.R')
library(shiny); print(source('~/git/nextWordApp/nextWord.R')$value)
getwd()
print(source('~/git/nextWordApp/nextWord.R')$value)
library(shiny); print(source('~/git/nextWordApp/nextWord.R')$value)
source('~/git/nextWordApp/nextWordApp.R')
getwd()
setwd("../nextWordApp")
dir()
source('~/git/nextWordApp/nextWordApp.R')
library(shiny); print(source('nextWordShiny.R')$value)
print(source('nextWordShiny.R')$value)
print(source('nextWordShiny.R')$value)
print(source('nextWordShiny.R')$value)
print(source('nextWordShiny.R')$value)
